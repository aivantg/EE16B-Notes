\documentclass[letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{mathrsfs}

\usepackage{afterpage}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{verse}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\usepackage{epstopdf}
\usepackage{circuitikz}
\usepackage[separate-uncertainty = true,multi-part-units=single]{siunitx}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage[toc,page]{appendix}
\usepackage{color}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{url}
\usepackage{multirow}
\usepackage{makecell}
\usepackage[round]{natbib}   % omit 'round' option if you prefer square brackets
\usepackage{titling}
\usepackage{siunitx}
\usepackage{physics}

\usepackage{setspace}
% \doublespacing
\usepackage{float}


\pgfplotsset{compat=1.14}

%  Special math symbols
%       floor, ceiling, angled brackets
%-----------------------------------------------------------------------
\newcommand{\floor}[1]{\left\lfloor #1\right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1\right\rceil}
\newcommand{\etal}{\textit{et al.}}
\newcommand{\RE}{\mathbb{R}}        % real space
\newcommand{\ZZ}{\mathbb{Z}}        % integers
\newcommand{\NN}{\mathbb{N}}        % natural numbers
\newcommand{\eps}{{\varepsilon}}    % prettier epsilon
%-----------------------------------------------------------------------
%  Tighter lists
%-----------------------------------------------------------------------
\newenvironment{itemize*}% Tighter itemized list
  {\begin{itemize}%
    \setlength{\itemsep}{-0.5ex}%
    \setlength{\parsep}{0pt}}%
  {\end{itemize}}
\newenvironment{description*}% Tighter description list
  {\begin{description}%
    \setlength{\itemsep}{-0.5ex}%
    \setlength{\parsep}{0pt}}%
  {\end{description}}
\newenvironment{enumerate*}% Tighter enumerated list
  {\begin{enumerate}%
    \setlength{\itemsep}{-0.5ex}%
    \setlength{\parsep}{0pt}}%
  {\end{enumerate}}
%-----------------------------------------------------------------------
% Typing shortcuts
%-----------------------------------------------------------------------
\newcommand{\X}{\mathbb{X}}
\newcommand{\SG}{\mathbf{S}}
\newcommand{\GE}{\mathcal{G}}
\newcommand{\ST}{\,:\,}
\renewcommand{\tilde}[1]{\widetilde{#1}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\sq}{\square}
\newcommand{\half}[1]{\frac{#1}{2}}
\newcommand{\inv}[1]{\frac{1}{#1}}
\newcommand{\alg}{\textsf{SplitReduce}}
\newcommand{\sz}[1]{\sigma_{#1}}
\newcommand{\LL}{\mathcal{L}}
\newcommand{\softOmega}{\widetilde{\Omega}} 
\newcommand{\softO}{\widetilde{O}}
\newcommand{\OO}{O^*}  %or \widetilde{O}?

\newcommand{\dx}{\mathrm{d}x}
\newcommand{\dy}{\mathrm{d}y}
\newcommand{\dz}{\mathrm{d}z}
\newcommand{\dt}{\mathrm{d}t}
\newcommand{\du}{\mathrm{d}u}
\newcommand{\dtheta}{\mathrm{d}\theta}
\newcommand{\dq}{\mathrm{d}q}
\newcommand{\diff}{\mathrm{d}}
\newcommand{\dV}{\mathrm{d}V}
\newcommand{\dL}{\mathrm{d}L}
\newcommand{\dA}{\mathrm{d}A}
\newcommand{\dH}{\mathrm{d}H}
\newcommand{\df}{\mathrm{d}f}
\newcommand{\dg}{\mathrm{d}g}
\newcommand{\dr}{\mathrm{d}r}
\newcommand{\dw}{\mathrm{d}w}
\newcommand{\dI}{\mathrm{d}I}

\newcommand*\len[1]{\overline{#1}}


\newcommand\note[1]{\marginpar{\textcolor{red}{#1}}}
\newcommand*{\tageq}{\refstepcounter{equation}\tag{\theequation}}

\newcommand*{\equals}{=}

\usepackage{fancyhdr}

\pgfplotscreateplotcyclelist{grayscale}{
    thick,white!10!black,mark=x,mark options=solid, dashed\\%
    thick,white!20!black,mark=o,mark options=solid\\%
}

\newcommand{\mat}[1]{\ensuremath{\begin{bmatrix}#1\end{bmatrix}}}
\newcommand{\cat}[1]{\ensuremath{\begin{vmatrix}#1\end{vmatrix}}}
\newcommand{\eqn}[1]{\begin{alignat*}{2}#1\end{alignat*}}
\newcommand{\p}[2]{\frac{\partial #1}{\partial #2}}
\newcommand*{\thus}{&\implies\quad&}

\newcommand{\answer}[1]{\framebox{$\displaystyle #1 $}}

\newcommand{\shrug}[1][]{%
\begin{tikzpicture}[baseline,x=0.8\ht\strutbox,y=0.8\ht\strutbox,line width=0.125ex,#1]
\def\arm{(-2.5,0.95) to (-2,0.95) (-1.9,1) to (-1.5,0) (-1.35,0) to (-0.8,0)};
\draw \arm;
\draw[xscale=-1] \arm;
\def\headpart{(0.6,0) arc[start angle=-40, end angle=40,x radius=0.6,y radius=0.8]};
\draw \headpart;
\draw[xscale=-1] \headpart;
\def\eye{(-0.075,0.15) .. controls (0.02,0) .. (0.075,-0.15)};
\draw[shift={(-0.3,0.8)}] \eye;
\draw[shift={(0,0.85)}] \eye;
% draw mouth
\draw (-0.1,0.2) to [out=15,in=-100] (0.4,0.95); 
\end{tikzpicture}}


\pagestyle{fancy}
\fancyhf{}
\rhead{Rahul Arya}
\lhead{EE 16B}
\cfoot{\thepage}

\title{Lecture 11 - Notes}
\author{Rahul Arya}
\date{February 2019}
\begin{document}

\maketitle

\section{Overview}
Last lecture, we saw how to model a continuous time system by approximating it as the discrete time system
\[
    \vec{x}[i + 1] = A\vec{x}[i] + \vec{u}[i],
\]
where $\vec{x}[i]$ and $\vec{u}[i]$ approximate the values of $\vec{x}$ and $\vec{u}$ near time $t = i\Delta$, where $\Delta$ was some fixed (small) time interval.

For the remainder of this module, we will almost entirely disregard the fact that our system may in fact really be continuous, focusing entirely on questions related to our discrete-time model. After all, in reality, most electronic control systems (like the MSP that we will use to develop a ``robot car'') have some intrinsic $\Delta$ in their ability to sample $\vec{x}$ and vary their output $\vec{u}$, so even if we knew that $\vec{x}$ varied within the interval $\Delta$, we would not be able to measure or react to this variation within the time interval.

\section{Special Cases of Controllability}
A natural problem to address is that of \emph{controllability} - in essence, given observations of $\vec{x}$ and some control over the input $\vec{u}$, how can we make $\vec{x}$ approach some target $\vec{x}^*$ over time? Clearly, if we have full control over $\vec{u}[i]$, this problem is easy! Given some $\vec{x}[0]$, we may choose $\vec{u}[0] = \vec{x}^* - A\vec{x}[0]$, to drive $\vec{x}[1]$ to our desired state in a single time step.

However, in reality, we rarely have full control over the input $\vec{u}[i]$. Imagine, for instance, that our state equation modelled the behavior of a circuit connected to some input voltage that we can vary. We saw in lecture 9 that the state vector of a circuit may include many components, like the voltages across capacitors or the currents through inductors, none of which we can change. Therefore, we may use the following equation to obtain a more accurate model of our system:
\[
    \vec{x}[i + 1] = A\vec{x}[i] + B\vec{u}[i].
\]
Notice the new matrix $B$, which constrains how our input $\vec{u}$ can influence the evolution of our system. For instance, in a simple system with a two-dimensional state, the case of
\[
    B = \mat{0 \\ 1}
\]
would mean that our input can only directly affect the second state. For now, we will not complicate matters further by considering nonlinear behavior or noise, so we can treat the above discrete-time equation as an accurate model of our system.

Before, we were always able to choose a $\vec{u}[0]$ to get to our target state in a single time step, no matter what the initial state $\vec{x}[0]$ was. Let's try doing the same thing now for arbitrary $B$:
\eqn{
    && \vec{x}[1] &= \vec{x}^* \\
    \thus A\vec{x}[0] + B\vec{u}[0] &= \vec{x}^* \\
    \thus B\vec{u}[0] &= \vec{x}^* - A\vec{x}[0].
}
Observe here that we can only achieve our desired state if $\vec{x}^* - A\vec{x}[0] \in \text{range}(B)$, which is not always the case (since $B$ is may be a ``tall'' matrix). Let $n$ be the dimension of $\vec{x}$ - in other words, let $\vec{x}$ be made up of $n$ scalar components. For \emph{any} desired state to be reachable, $B$ would have to span all of $\mathbb{R}^n$, and so be of rank $n$.

So, is all hope lost? Not necessarily. Recall that we only wanted to achieve our target state at \emph{some point}, not necessarily in a single time step. Consider the state transition matrix
\[
    A = \mat{1 & -1 \\ 2 & 1},
\]
with $B$ defined as before (i.e. only allowing us to affect the second state). Since $B$ has only one column, our control input $\vec{u}$ is one dimensional, and so can be treated as a scalar $u$. We know that, after $1$ time step, we may only reach the states that can be written as
\[
    \vec{x}[1] = A\vec{x}[0] + Bu[0]
\]
for a suitable choice of control input $u[0]$. Since $B$ is not of rank $2$, the set of viable $\vec{x}[1]$ does not yet span all of $\mathbb{R}^2$. However, now consider the set of states that are reachable after $2$ time steps. By our state transition equation, they can be written as
\eqn{
    && \vec{x}[2] &= A\vec{x}[1] + Bu[1] \\
    &&&= A(A\vec{x}[0] + Bu[0]) + Bu[1] \\
    &&&= A^2\vec{x}[0] + ABu[0] + Bu[1].
}
Notice that if the vectors $AB$ and $B$ together span all of $\mathbb{R}^2$, then we would be able to choose coefficients $u[0]$ and $u[1]$ to reach \emph{any desired} $\vec{x}[2]$, meaning that the system is controllable in $2$ time steps.

\section{General Controllability}
Generalizing our equation for $\vec{x}[2]$ to the case of multidimensional control inputs (i.e. when $B$ has $k$ columns, not just $1$) and arbitrarily large state dimensions $n$, we obtain
\[
    \vec{x}[2] = A^2\vec{x}[0] + AB\vec{u}[0] + B\vec{u}[1]
\]
from an analogous calculation.

This can be reexpressed as
\[
    \vec{x}[2] = A^2\vec{x}[0] + \mat{AB & B} \mat{\vec{u}[0] \\ \vec{u}[1]},
\]
using stacked matrix notation.

More generally, we know that
\[
    \vec{x}[i] = A^n\vec{x}[0] + \mat{B & AB & \cdots & A^{i - 1}B} \mat{\vec{u}[i - 1] \\ \vdots \\ \vec{u}[0]}.
\]
Therefore, we find that our system is controllable after $i$ time steps if and only if the matrix
\[
    \mathscr{C} = \mat{B & AB & \cdots & A^{i - 1}B}
\]
has full rank.

The question now becomes - is \emph{every} system controllable after sufficiently many time steps? That is to say, is it true that, for any $n\times n$ matrix $A$ and $n\times k$ matrix $B$, there exists some constant $i$ such that the matrix $\mat{B & AB & \cdots & A^{i - 1}B}$ is of full rank?

Clearly, this is not the case - after all, consider the case when the input has no effect on the state transition, when $B = 0$ ! But it may not be the case even in nontrivial cases - consider, for instance
\eqn{
    && A &= \mat{2 & 3 \\ 0 & 4} \\
    && B &= \mat{1 \\ 2}.
}
Observe that
\eqn{
    && AB &= \mat{2 \\ 4} \\
    && A^2B &= \mat{4 \\ 8},
}
and so on, so all the columns of the stacked matrix will be linearly dependent. Thus, even though this system has what is inarguably a nontrivial state transition equation, it is still not controllable even after infinitely many time steps.

\section{Determining Controllability}
We will now attempt to devise a general method of determining whether or not a system is controllable. In essence, we want to know whether the infinite sequence
\[
    \text{range}(\mat{B}), \text{range}(\mat{ B & AB}), \text{range}(\mat{B & AB & A^2B}), \ldots
\]
will ever reach $\mathbb{R}^n$.

Our approach will rely on the following key observation: that if all the columns of $A^iB$ is linearly dependent on the previous $A^jB$ for $j < i$, then all the columns of $A^{i+1}B$ will also be linearly dependent on the same set of $A^jB$. That is to say, if the ranges in the above sequence ever stop growing for even a single iteration, then they will never start growing again.

For simplicity, we will conduct our proof under the assumption that $B$ is a column vector, so all the $A^iB$ have only one column. However, the exact same approach works in the most general case, except that the notation is a lot more messy.

By the condition of the observation and the definition of linear dependence, there exist coefficients $\alpha_j$ such that
\[
    A^iB = \sum_{j = 0}^{i - 1} \alpha_j A^{j}B.
\]
Thus, we may write
\eqn{
    && A^{i + 1}B &= A(A^iB) \\
    &&&= A\sum_{j = 0}^{i - 1} \alpha_j A^{j}B \\
    &&&= \sum_{j=0}^{i-1}\alpha_jA^{j+1}B \\
    &&&= \sum_{j=1}^{i}\alpha_{j-1}A^jB \\
    &&&= \alpha_{i-1}A^iB + \sum_{j=1}^{i - 1}\alpha_{j-1}A^jB \\
    &&&= \sum_{j = 0}^{i - 1} \alpha_{i-1}\alpha_j A^{j}B + \sum_{j=1}^{i - 1}\alpha_{j-1}A^jB,
}
so $A^{i+1}B$ can be expressed as a linear combination of the same preceding $A^jB$.

With this result, we are on the road to developing an algorithm to determine the controllability of a system. Iteratively construct the sequence of ranges as described above. If the dimension of the ranges ever stops growing, we know that the dimension will never start to grow again as the sequence continues, so we know what possible $\vec{x}^*$ are reachable even after infinitely many time steps. The only issue is if the dimension of the ranges never stops growing. But this can never be the case, since the dimension of the ranges is bounded by $n$ (since they are all subspaces of $\mathbb{R}^n$)!

Thus, after $n$ iterations, the ranges will either have stopped growing during one of the intermediate iterations, or would have reached rank $n$ and so will not be able to continue to grow thereafter. Consequently, by considering the subspace
\[
    \text{range}(\mat{B & AB & \ldots & A^{n-1}B})
\]
we will be able to determine whether our system is controllable. If this range is of dimension $n$ (and so spans the entirety of $\mathbb{R}^n$), then our system is controllable. Otherwise, it is not. Typically, we refer to this span as $\text{range}(\mathscr{C})$, where $\mathscr{C}$ is defined as
\[
    \mathscr{C} = \mat{B & AB & \cdots & A^{n - 1}B}.
\]

An immediate consequence of this result is that a system is controllable if and only if it is controllable in at most $n$ timesteps.

The next natural question is as follows: even if our system is controllable, how do we calculate the necessary inputs needed to reach a desired state $\vec{x}^*$? As it turns out, this is straightforward, if we consider the stacked matrix representation of $\vec{x}[n] = \vec{x}^*$:
\[
    \vec{x}^* = A^n\vec{x}[0] + \mat{B & AB & \cdots & A^{n - 1}B} \mat{\vec{u}[n - 1] \\ \vdots \\ \vec{u}[0]} = A^n\vec{x}[0] + \mathscr{C}\mat{\vec{u}[n - 1] \\ \vdots \\ \vec{u}[0]}.
\]
Rearranging, we obtain
\[
    \mathscr{C}\mat{\vec{u}[n - 1] \\ \vdots \\ \vec{u}[0]} = \vec{x}^* - A^n\vec{x}[0].
\]
Using Gaussian elimination, we can now determine the sequence of control inputs to make, if such a sequence exists. Thus, we have resolved the problem that was initially posed at the beginning of the lecture.

Next time, we will consider the dual problem of \emph{observability} - given a series of observations of a system and the corresponding inputs, can we determine the original state $\vec{x}[0]$?

\end{document}
